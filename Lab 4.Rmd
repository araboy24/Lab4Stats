---
title: "Lab 4: MATH 4753"
author: "Eid Zaben"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
    theme: spacelab
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Task 1

```{r}
getwd()
```

# Task 2

```{r}
spruce.df = read.csv("SPRUCE.csv")
tail(spruce.df)
```

# Task 3

```{r}
library(s20x)
with (spruce.df, 
  trendscatter(Height~BHDiameter,f=0.5)
)

spruce.lm=with(spruce.df,lm(Height~BHDiameter)) 

height.res = residuals(spruce.lm)

height.fit=fitted(spruce.lm)

plot(height.fit,height.res)

trendscatter( height.fit,height.res)
```

The shape seen in the plot of comparing the fitted and residual values of height is a concave down parabolic graph that increases from 12 to 18 and decreases from 18 to 24. Compared to the first plot, the difference is due to residuals and fitted being plotted instead of the BHdiameter and Height. This indicates that a linear model is not a sufficient representation. 

```{r}
plot(spruce.lm, which =1)
normcheck(spruce.lm,shapiro.wilk = TRUE)
```

The p value of the Shapiro-Wilk test is 0.29. The null hypothesis in this case is accepted because the p value is larger than 0.05, so the error should be distributed normally. 

Since the plot of residuals vs fitted values in parabolic and not straight, a straight line model would not work properly. The noise needs to be found instead of the signal. The model also needs to be adjusted in order to accurately portray the data. 


# Task 4


```{r}
quad.lm=lm(Height~BHDiameter + I(BHDiameter^2),data=spruce.df)
summary(quad.lm)
```

```{r}
plot(spruce.df)

plt = function(x) { 
  quad.lm$coef[1] + quad.lm$coef[2] * x + quad.lm$coef[3]*x^2
  }

curve(plt, lwd = 2, col = "red", add = TRUE)
```

```{r}
quad.fit = fitted(quad.lm)

plot(quad.lm, which = 1)
```

```{r}
normcheck(quad.lm, shapiro.wilk = TRUE)
```

The p value is 0.684, so the null hypothesis is accepted because the p value is larger than 0.05. There is no noticeable trend in the plot between the residuals and the fitted values. Because of this, a quadratic model is better than a linear model. 

# Task 5

```{r}
summary(quad.lm)
```

Beta Hat 0 = 0.860896

Beta Hat 1 = 1.469592

Beta Hat 2 = -0.027457

```{r}
ciReg(quad.lm)
```

The fitted line equation is:

Height = 0.860896 + 1.469592x + -0.027457x^2

```{r}
predict(quad.lm, data.frame(BHDiameter =c(15, 18, 20)))
```

These predictions are larger than the previous one's that were found with spruce.lm. This is because quad.lm follows quadratic growth.

```{r}
summary(quad.lm)$r.squared
summary(spruce.lm)$r.squared
```
The R squared from the quaratic is larger. 

```{r}
summary(quad.lm)$adj.r.squared
summary(spruce.lm)$adj.r.squared
```

The adjusted R squared shows how well a model matches the data. A larger R squares means the model improved. This indicates that quad.lm is a better fit. 

Multiple R squared is an indication of how well a model describes the data independent of the number of data points. 

quad.lm explains the most variability in height because its R squared values are larger. 

```{r}
anova(spruce.lm)
anova(quad.lm)
```

Since quad.lm has a smaller RSS value, it is a better representation of the data. 

```{r}
height.qfit = fitted(quad.lm)
TSS = sum((spruce.df$Height - mean(spruce.df$Height))^2)
TSS

MSS = sum((height.qfit - mean(spruce.df$Height))^2)
MSS

RSS = sum((spruce.df$Height - height.qfit)^2)
RSS

MSS/TSS
```

# Task 6

```{r}
cooks20x(quad.lm)
```

Cooks distance plot is used to find out how impactful certain data points are towards the regression analysis. The larger the distance is at a certain point, the more of an effect it has. It can be used to find outliers more easily and determine if the outlier is having a large effect or not. 

Since the distance at 24 is largest, that observation number has the largest impact on the regression analysis.

```{r}
quad2.lm = lm(Height~BHDiameter + I(BHDiameter ^ 2), data = spruce.df[-24,])
summary(quad2.lm)
summary(quad.lm)
```

The multiple and adjusted R squared values are larger without the 24 being included in the data going from these values in quad.lm:

Multiple R-squared: 0.7741,	Adjusted R-squared:  0.7604

To these values in quad2.lm:

Multiple R-squared:  0.8159,	Adjusted R-squared:  0.8044 

The min and median are larger without the 24 included. The max however becomes smaller, causing the range to shrink. 

In conclusion, Cooks plot correctly found a very impactful value because removing it caused R-squared values to increase by about 0.03.

# Task 7

```{r}
spruce2.df = within(spruce.df, X <- (BHDiameter - 18) * (BHDiameter > 18))
lmp = lm(Height~BHDiameter + X, data = spruce2.df)
tmp = summary(lmp)
myf = function(x, coef) {
  coef[1] + coef[2] * (x) + coef[3] * (x-18) * (x-18>0)
}
plot(spruce.df, main="Piecewise Regression")
myf(0, coef=tmp$coefficients[,"Estimate"])
curve(myf(x, coef=tmp$coefficients[,"Estimate"]), add = TRUE, lwd=2, col="Blue")
abline(v=18)
text(18, 14, paste("R sq.=", round(tmp$r.squared, 4)))
```

# Task 8

```{r}
install.packages("C:/Users/eidza/OneDrive/Documents/MATH4753/RPACKAGES/MATH4753EidZaben24_0.1.0.tar.gz", repos = NULL, type = "source")
library("MATH4753EidZaben24")
sp.df <- myread2("SPRUCE.csv")
head(sp.df)
```

This function takes in the name of a csv file and creates a dataframe. It returns the dataframe into a variable that is assigned to the functions return value. 

In this case the variable sp.df is used, and the first six lines are outputted using head. 